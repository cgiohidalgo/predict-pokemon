{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from keras import Sequential\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from keras.layers import Conv2D, BatchNormalization, Dropout, Flatten, Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Ruta relativa a la carpeta de imágenes (si el código y las imágenes están en el mismo directorio)\n","images_path = '/Users/giovannyhidalgo/Desktop/archive/images/images/'\n","\n","# Función para cargar y redimensionar imágenes\n","def load_and_resize_image(image_path):\n","    image = cv2.imread(image_path)\n","    if image is not None:\n","        resized_image = cv2.resize(image, (28, 28))\n","        return resized_image\n","    else:\n","        return None\n","\n","X_data = []\n","Y_data = []\n","\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/giovannyhidalgo/Desktop/archive/images/images/\n"]}],"source":["print(images_path)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Cargar imágenes y generar datos de entrenamiento\n","for filename in os.listdir(images_path):\n","    image_path = os.path.join(images_path, filename)\n","    image = load_and_resize_image(image_path)\n","    if image is not None:\n","        X_data.append(image)\n","        img_name = filename.split('.')[0]\n","        Y_data.append(img_name)\n","\n","        # Generar 100 imágenes adicionales para el Pokémon actual usando el generador de datos\n","        for _ in range(100):\n","            random_img = datagen.random_transform(image)\n","            X_data.append(random_img)\n","            Y_data.append(img_name)\n","\n","if not X_data or not Y_data:\n","    raise ValueError(\"No se encontraron imágenes válidas en el directorio.\")\n","\n","X_data = np.array(X_data).astype('float32') / 255.0\n","\n","encoder = LabelEncoder()\n","Y_data = encoder.fit_transform(Y_data)\n","Y_data = to_categorical(Y_data)\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["np.save('encoder_classes.npy', encoder.classes_)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Generador de datos de imágenes con configuración optimizada\n","\n","datagen = ImageDataGenerator(\n","    rotation_range=45,\n","    zoom_range=0.30,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","340/340 [==============================] - ETA: 0s - loss: 5.3999 - accuracy: 0.0589\n","Epoch 1: loss improved from inf to 5.39990, saving model to weights.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["340/340 [==============================] - 233s 682ms/step - loss: 5.3999 - accuracy: 0.0589 - val_loss: 4.0840 - val_accuracy: 0.1811 - lr: 0.0010\n","Epoch 2/20\n","340/340 [==============================] - ETA: 0s - loss: 3.9364 - accuracy: 0.1947\n","Epoch 2: loss improved from 5.39990 to 3.93639, saving model to weights.h5\n","340/340 [==============================] - 309s 907ms/step - loss: 3.9364 - accuracy: 0.1947 - val_loss: 2.9204 - val_accuracy: 0.3609 - lr: 0.0010\n","Epoch 3/20\n","340/340 [==============================] - ETA: 0s - loss: 3.1065 - accuracy: 0.3218\n","Epoch 3: loss improved from 3.93639 to 3.10646, saving model to weights.h5\n","340/340 [==============================] - 316s 928ms/step - loss: 3.1065 - accuracy: 0.3218 - val_loss: 2.1539 - val_accuracy: 0.5176 - lr: 0.0010\n","Epoch 4/20\n","340/340 [==============================] - ETA: 0s - loss: 2.5195 - accuracy: 0.4257\n","Epoch 4: loss improved from 3.10646 to 2.51948, saving model to weights.h5\n","340/340 [==============================] - 306s 899ms/step - loss: 2.5195 - accuracy: 0.4257 - val_loss: 1.6141 - val_accuracy: 0.6200 - lr: 0.0010\n","Epoch 5/20\n","340/340 [==============================] - ETA: 0s - loss: 2.1157 - accuracy: 0.5034\n","Epoch 5: loss improved from 2.51948 to 2.11574, saving model to weights.h5\n","340/340 [==============================] - 261s 767ms/step - loss: 2.1157 - accuracy: 0.5034 - val_loss: 1.2762 - val_accuracy: 0.7053 - lr: 0.0010\n","Epoch 6/20\n","340/340 [==============================] - ETA: 0s - loss: 1.8173 - accuracy: 0.5695\n","Epoch 6: loss improved from 2.11574 to 1.81734, saving model to weights.h5\n","340/340 [==============================] - 261s 765ms/step - loss: 1.8173 - accuracy: 0.5695 - val_loss: 1.0751 - val_accuracy: 0.7498 - lr: 0.0010\n","Epoch 7/20\n","340/340 [==============================] - ETA: 0s - loss: 1.6033 - accuracy: 0.6166\n","Epoch 7: loss improved from 1.81734 to 1.60330, saving model to weights.h5\n","340/340 [==============================] - 238s 698ms/step - loss: 1.6033 - accuracy: 0.6166 - val_loss: 0.8947 - val_accuracy: 0.7945 - lr: 0.0010\n","Epoch 8/20\n","340/340 [==============================] - ETA: 0s - loss: 1.4396 - accuracy: 0.6500\n","Epoch 8: loss improved from 1.60330 to 1.43958, saving model to weights.h5\n","340/340 [==============================] - 248s 729ms/step - loss: 1.4396 - accuracy: 0.6500 - val_loss: 0.7916 - val_accuracy: 0.8208 - lr: 0.0010\n","Epoch 9/20\n","340/340 [==============================] - ETA: 0s - loss: 1.2985 - accuracy: 0.6816\n","Epoch 9: loss improved from 1.43958 to 1.29852, saving model to weights.h5\n","340/340 [==============================] - 241s 707ms/step - loss: 1.2985 - accuracy: 0.6816 - val_loss: 0.6529 - val_accuracy: 0.8547 - lr: 0.0010\n","Epoch 10/20\n","340/340 [==============================] - ETA: 0s - loss: 1.2069 - accuracy: 0.7024\n","Epoch 10: loss improved from 1.29852 to 1.20687, saving model to weights.h5\n","340/340 [==============================] - 283s 832ms/step - loss: 1.2069 - accuracy: 0.7024 - val_loss: 0.6412 - val_accuracy: 0.8506 - lr: 0.0010\n","Epoch 11/20\n","340/340 [==============================] - ETA: 0s - loss: 1.1030 - accuracy: 0.7239\n","Epoch 11: loss improved from 1.20687 to 1.10298, saving model to weights.h5\n","340/340 [==============================] - 237s 696ms/step - loss: 1.1030 - accuracy: 0.7239 - val_loss: 0.5493 - val_accuracy: 0.8689 - lr: 0.0010\n","Epoch 12/20\n","340/340 [==============================] - ETA: 0s - loss: 1.0418 - accuracy: 0.7398\n","Epoch 12: loss improved from 1.10298 to 1.04184, saving model to weights.h5\n","340/340 [==============================] - 222s 654ms/step - loss: 1.0418 - accuracy: 0.7398 - val_loss: 0.4997 - val_accuracy: 0.8833 - lr: 0.0010\n","Epoch 13/20\n","340/340 [==============================] - ETA: 0s - loss: 0.9710 - accuracy: 0.7576\n","Epoch 13: loss improved from 1.04184 to 0.97099, saving model to weights.h5\n","340/340 [==============================] - 240s 705ms/step - loss: 0.9710 - accuracy: 0.7576 - val_loss: 0.4700 - val_accuracy: 0.8854 - lr: 0.0010\n","Epoch 14/20\n","340/340 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.7695\n","Epoch 14: loss improved from 0.97099 to 0.90801, saving model to weights.h5\n","340/340 [==============================] - 304s 894ms/step - loss: 0.9080 - accuracy: 0.7695 - val_loss: 0.4299 - val_accuracy: 0.8976 - lr: 0.0010\n","Epoch 15/20\n","340/340 [==============================] - ETA: 0s - loss: 0.8708 - accuracy: 0.7778\n","Epoch 15: loss improved from 0.90801 to 0.87080, saving model to weights.h5\n","340/340 [==============================] - 312s 916ms/step - loss: 0.8708 - accuracy: 0.7778 - val_loss: 0.3899 - val_accuracy: 0.9093 - lr: 0.0010\n","Epoch 16/20\n","340/340 [==============================] - ETA: 0s - loss: 0.8156 - accuracy: 0.7911\n","Epoch 16: loss improved from 0.87080 to 0.81563, saving model to weights.h5\n","340/340 [==============================] - 264s 776ms/step - loss: 0.8156 - accuracy: 0.7911 - val_loss: 0.3667 - val_accuracy: 0.9127 - lr: 0.0010\n","Epoch 17/20\n","340/340 [==============================] - ETA: 0s - loss: 0.7852 - accuracy: 0.8006\n","Epoch 17: loss improved from 0.81563 to 0.78521, saving model to weights.h5\n","340/340 [==============================] - 317s 931ms/step - loss: 0.7852 - accuracy: 0.8006 - val_loss: 0.3393 - val_accuracy: 0.9197 - lr: 0.0010\n","Epoch 18/20\n","340/340 [==============================] - ETA: 0s - loss: 0.7473 - accuracy: 0.8090\n","Epoch 18: loss improved from 0.78521 to 0.74730, saving model to weights.h5\n","340/340 [==============================] - 293s 859ms/step - loss: 0.7473 - accuracy: 0.8090 - val_loss: 0.3530 - val_accuracy: 0.9127 - lr: 0.0010\n","Epoch 19/20\n","340/340 [==============================] - ETA: 0s - loss: 0.7185 - accuracy: 0.8155\n","Epoch 19: loss improved from 0.74730 to 0.71847, saving model to weights.h5\n","340/340 [==============================] - 374s 1s/step - loss: 0.7185 - accuracy: 0.8155 - val_loss: 0.2860 - val_accuracy: 0.9343 - lr: 0.0010\n","Epoch 20/20\n","340/340 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.8186\n","Epoch 20: loss improved from 0.71847 to 0.69815, saving model to weights.h5\n","340/340 [==============================] - 452s 1s/step - loss: 0.6981 - accuracy: 0.8186 - val_loss: 0.2883 - val_accuracy: 0.9343 - lr: 0.0010\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x13f1935d0>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Arquitectura del modelo (más profunda para mejorar el rendimiento)\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=X_train.shape[1:]))\n","# Agregar más capas convolucionales y de normalización aquí\n","# ...\n","model.add(Flatten())\n","model.add(Dropout(0.4))\n","model.add(Dense(Y_train.shape[1], activation='softmax'))\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# Entrenar el modelo con configuración adicional\n","model.fit(datagen.flow(X_train, Y_train, batch_size=192),\n","          epochs=20,\n","          steps_per_epoch=X_train.shape[0] // 192,\n","          validation_data=(X_test, Y_test),\n","          callbacks=[EarlyStopping(monitor='loss', min_delta=1e-10, patience=20, verbose=1),\n","                     ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, verbose=1),\n","                     ModelCheckpoint(filepath='weights.h5', monitor='loss',\n","                                     save_best_only=True, verbose=1)])\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Guardar el modelo\n","model.save('model.h5')\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["511/511 [==============================] - 51s 99ms/step - loss: 0.2883 - accuracy: 0.9343\n","Evaluación en datos de prueba:\n","Pérdida: 0.28826916217803955\n","Precisión: 0.9342837929725647\n","2043/2043 [==============================] - 103s 50ms/step - loss: 0.2753 - accuracy: 0.9365\n","Evaluación en datos de entrenamiento:\n","Pérdida: 0.27532312273979187\n","Precisión: 0.936543881893158\n"]}],"source":["# Evaluar el modelo en datos de prueba y entrenamiento\n","evaluation_test = model.evaluate(X_test, Y_test)\n","print(\"Evaluación en datos de prueba:\")\n","print(\"Pérdida:\", evaluation_test[0])\n","print(\"Precisión:\", evaluation_test[1])\n","\n","evaluation_train = model.evaluate(X_train, Y_train)\n","print(\"Evaluación en datos de entrenamiento:\")\n","print(\"Pérdida:\", evaluation_train[0])\n","print(\"Precisión:\", evaluation_train[1])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Función para cargar, redimensionar y preprocesar una nueva imagen\n","def load_and_preprocess_image(image_path):\n","    image = cv2.imread(image_path)\n","    if image is not None:\n","        resized_image = cv2.resize(image, (28, 28))\n","        preprocessed_image = resized_image.astype('float32') / 255.0\n","        return preprocessed_image\n","    else:\n","        return None"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 41ms/step\n","Predicción de Pokémon: tapu-koko\n"]}],"source":["\n","\n","# Función para realizar una predicción de Pokémon a partir de una nueva imagen\n","def predict_pokemon(image_path):\n","    preprocessed_image = load_and_preprocess_image(image_path)\n","    if preprocessed_image is not None:\n","        preprocessed_image = preprocessed_image.reshape(1, 28, 28, 3)  # Agregar dimensión del lote (batch) a la imagen\n","        prediction_probabilities = model.predict(preprocessed_image)\n","        predicted_class_index = np.argmax(prediction_probabilities)\n","        predicted_pokemon = encoder.inverse_transform([predicted_class_index])[0]\n","        return predicted_pokemon\n","    else:\n","        return \"No se pudo cargar la imagen.\"\n","\n","# Ejemplo de cómo usar la función de predicción con una nueva imagen\n","new_image_path = '/Users/giovannyhidalgo/Desktop/b.png'\n","#new_image_path = '/Users/giovannyhidalgo/Desktop/archive/images/images1/pikachu.png'\n","\n","predicted_pokemon = predict_pokemon(new_image_path)\n","print(\"Predicción de Pokémon:\", predicted_pokemon)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
